{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb293a9c",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff31d863",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69ce9de",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6737fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"/workspaces/codespaces-jupyter/data/mental_heath_unbanlanced.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba43892f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"/workspaces/codespaces-jupyter/data/mental_health_combined_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38340627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unique_ID</th>\n",
       "      <th>text</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>oh my gosh</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>trouble sleeping, confused mind, restless hear...</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>All wrong, back off dear, forward doubt. Stay ...</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>I've shifted my focus to something else but I'...</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>I'm restless and restless, it's been a month n...</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49607</th>\n",
       "      <td>NaN</td>\n",
       "      <td>i can't explain it but i know that i don't wan...</td>\n",
       "      <td>Depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49608</th>\n",
       "      <td>NaN</td>\n",
       "      <td>nobody ever told me that when i started treatm...</td>\n",
       "      <td>Depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49609</th>\n",
       "      <td>NaN</td>\n",
       "      <td>my wife and i split up in 2012/2013. she had a...</td>\n",
       "      <td>Depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49610</th>\n",
       "      <td>NaN</td>\n",
       "      <td>A close family member committed suicideI just ...</td>\n",
       "      <td>Suicidal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49611</th>\n",
       "      <td>NaN</td>\n",
       "      <td>i am a high school english teacher. i am also ...</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49612 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unique_ID                                               text  \\\n",
       "0            0.0                                         oh my gosh   \n",
       "1            1.0  trouble sleeping, confused mind, restless hear...   \n",
       "2            2.0  All wrong, back off dear, forward doubt. Stay ...   \n",
       "3            3.0  I've shifted my focus to something else but I'...   \n",
       "4            4.0  I'm restless and restless, it's been a month n...   \n",
       "...          ...                                                ...   \n",
       "49607        NaN  i can't explain it but i know that i don't wan...   \n",
       "49608        NaN  nobody ever told me that when i started treatm...   \n",
       "49609        NaN  my wife and i split up in 2012/2013. she had a...   \n",
       "49610        NaN  A close family member committed suicideI just ...   \n",
       "49611        NaN  i am a high school english teacher. i am also ...   \n",
       "\n",
       "           status  \n",
       "0         Anxiety  \n",
       "1         Anxiety  \n",
       "2         Anxiety  \n",
       "3         Anxiety  \n",
       "4         Anxiety  \n",
       "...           ...  \n",
       "49607  Depression  \n",
       "49608  Depression  \n",
       "49609  Depression  \n",
       "49610    Suicidal  \n",
       "49611     Anxiety  \n",
       "\n",
       "[49612 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab590e35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "status\n",
       "Normal        18391\n",
       "Depression    14506\n",
       "Suicidal      11212\n",
       "Anxiety        5503\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0db43b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {\n",
    "    \"Normal\":0,\n",
    "    \"Anxiety\": 1,\n",
    "    \"Depression\": 2,\n",
    "    \"Suicidal\": 3\n",
    "}\n",
    "\n",
    "df_train[\"label\"] = df_train[\"status\"].map(label_map)\n",
    "df_test[\"label\"] = df_test[\"status\"].map(label_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b03258d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    25\n",
       "1    25\n",
       "2    25\n",
       "3    25\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train_sampled = df_train.groupby('label').sample(n=25, random_state=42)\n",
    "display(df_train_sampled['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51a798ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    50\n",
       "1    50\n",
       "2    50\n",
       "3    50\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_test_sampled = df_train.groupby('label').sample(n=50, random_state=42)\n",
    "display(df_test_sampled['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e20dffd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = df_train_sampled[[\"text\", \"label\"]]\n",
    "val_ds  = df_test_sampled[[\"text\", \"label\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d976f9",
   "metadata": {},
   "source": [
    "# Load Pretrained BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ee7f3ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "392dfb407cd3403790292d328bcfd218",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mBertForSequenceClassification LOAD REPORT\u001b[0m from: bert-base-uncased\n",
      "Key                                        | Status     | \n",
      "-------------------------------------------+------------+-\n",
      "cls.seq_relationship.bias                  | UNEXPECTED | \n",
      "cls.predictions.transform.dense.bias       | UNEXPECTED | \n",
      "cls.predictions.transform.dense.weight     | UNEXPECTED | \n",
      "cls.predictions.transform.LayerNorm.bias   | UNEXPECTED | \n",
      "cls.predictions.bias                       | UNEXPECTED | \n",
      "cls.seq_relationship.weight                | UNEXPECTED | \n",
      "cls.predictions.transform.LayerNorm.weight | UNEXPECTED | \n",
      "classifier.weight                          | MISSING    | \n",
      "classifier.bias                            | MISSING    | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "- MISSING\u001b[3m\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\",\n",
    "    num_labels=4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bb75d5",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a41a6e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_f(batch):\n",
    "    return tokenizer(\n",
    "        batch['text'],\n",
    "        truncation=True,\n",
    "        padding = \"max_length\",\n",
    "        max_length=256\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "068303eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9a76fd6164a4a30b5c74f455865de3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "# Convert pandas DataFrame to Hugging Face Dataset\n",
    "hf_dataset = Dataset.from_pandas(train_ds)\n",
    "fh_dataset = Dataset.from_pandas(val_ds)\n",
    "\n",
    "# Now, use the map method from the Hugging Face datasets library\n",
    "tokenized_dataset = hf_dataset.map(\n",
    "    tokenize_f,\n",
    "    batched=True,\n",
    "    remove_columns=[\"text\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2781131d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be1eaca5f1e34ef4a22a532c32a833b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset_test = fh_dataset.map(\n",
    "    tokenize_f,\n",
    "    batched=True,\n",
    "    remove_columns=[\"text\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13a9b241",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset.set_format(\"torch\")\n",
    "tokenized_dataset_test.set_format(\"torch\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf48b2d3",
   "metadata": {},
   "source": [
    "# Define Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab959f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = evaluate.load(\"accuracy\")\n",
    "precision = evaluate.load(\"precision\")\n",
    "recall = evaluate.load(\"recall\")\n",
    "f1 = evaluate.load(\"f1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "62148a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=1)\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy.compute(predictions=predictions, references=labels)[\"accuracy\"],\n",
    "        \"precision\": precision.compute(predictions=predictions, references=labels, average=\"weighted\")[\"precision\"],\n",
    "        \"recall\": recall.compute(predictions=predictions, references=labels, average=\"weighted\")[\"recall\"],\n",
    "        \"f1\": f1.compute(predictions=predictions, references=labels, average=\"weighted\")[\"f1\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c7f1ea",
   "metadata": {},
   "source": [
    "# Training Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bf905c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./bert-sentiment\",\n",
    "    save_strategy=\"steps\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=5,\n",
    "    eval_strategy=\"steps\",\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=50,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ac9cdf",
   "metadata": {},
   "source": [
    "# Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "99bbbc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    eval_dataset=tokenized_dataset_test,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afeefdb7",
   "metadata": {},
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eec9dbbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function tqdm.__del__ at 0x7cdd19293ba0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/python/3.12.1/lib/python3.12/site-packages/tqdm/std.py\", line 1148, in __del__\n",
      "    self.close()\n",
      "  File \"/usr/local/python/3.12.1/lib/python3.12/site-packages/tqdm/notebook.py\", line 279, in close\n",
      "    self.disp(bar_style='danger', check_delay=False)\n",
      "    ^^^^^^^^^\n",
      "AttributeError: 'tqdm' object has no attribute 'disp'\n",
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='35' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 11:27, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3627844cf63490abd079abd3f6e299d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=35, training_loss=1.235215323311942, metrics={'train_runtime': 711.7948, 'train_samples_per_second': 0.702, 'train_steps_per_second': 0.049, 'total_flos': 65778945024000.0, 'train_loss': 1.235215323311942, 'epoch': 5.0})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472b93d8",
   "metadata": {},
   "source": [
    "# Final Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc54fdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = trainer.evaluate()\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52517d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def predict_sentiment(text):\n",
    "    model.eval()\n",
    "\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=256\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    probs = F.softmax(logits, dim=1)\n",
    "    predicted_class = torch.argmax(probs, dim=1).item()\n",
    "\n",
    "    return {\n",
    "        \"text\": text,\n",
    "        \"predicted_label\": predicted_class,\n",
    "        \"confidence\": probs[0][predicted_class].item()\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca136559",
   "metadata": {},
   "source": [
    "    \"Normal\":0,\n",
    "    \"Anxiety\": 1,\n",
    "    \"Depression\": 2,\n",
    "    \"Suicidal\": 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "72c692de",
   "metadata": {},
   "outputs": [],
   "source": [
    "thoughts = [\n",
    "    \"I had a calm evening reading a book and felt pretty content.\",\n",
    "    \"I can’t stop worrying that something will go wrong tomorrow.\",\n",
    "    \"Lately I feel empty and nothing seems to excite me anymore.\",\n",
    "    \"Sometimes I feel like everyone would be better off without me.\",\n",
    "    \"I’m nervous about small things and my heart starts racing for no reason.\",\n",
    "    \"Today was productive and I’m satisfied with how things went.\",\n",
    "    \"I don’t feel motivated to get out of bed these days.\",\n",
    "    \"I keep overthinking every conversation I had today.\",\n",
    "    \"I feel hopeless and don’t see much point in continuing like this.\",\n",
    "    \"Spent time with friends today and genuinely enjoyed it.\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "832d3c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: I had a calm evening reading a book and felt pretty content.\n",
      "Sentiment: {'text': 'I had a calm evening reading a book and felt pretty content.', 'predicted_label': 0, 'confidence': 0.3330972492694855}\n",
      "\n",
      "Thought: I can’t stop worrying that something will go wrong tomorrow.\n",
      "Sentiment: {'text': 'I can’t stop worrying that something will go wrong tomorrow.', 'predicted_label': 1, 'confidence': 0.3082188367843628}\n",
      "\n",
      "Thought: Lately I feel empty and nothing seems to excite me anymore.\n",
      "Sentiment: {'text': 'Lately I feel empty and nothing seems to excite me anymore.', 'predicted_label': 1, 'confidence': 0.31070810556411743}\n",
      "\n",
      "Thought: Sometimes I feel like everyone would be better off without me.\n",
      "Sentiment: {'text': 'Sometimes I feel like everyone would be better off without me.', 'predicted_label': 1, 'confidence': 0.30787914991378784}\n",
      "\n",
      "Thought: I’m nervous about small things and my heart starts racing for no reason.\n",
      "Sentiment: {'text': 'I’m nervous about small things and my heart starts racing for no reason.', 'predicted_label': 1, 'confidence': 0.29234549403190613}\n",
      "\n",
      "Thought: Today was productive and I’m satisfied with how things went.\n",
      "Sentiment: {'text': 'Today was productive and I’m satisfied with how things went.', 'predicted_label': 1, 'confidence': 0.3255098760128021}\n",
      "\n",
      "Thought: I don’t feel motivated to get out of bed these days.\n",
      "Sentiment: {'text': 'I don’t feel motivated to get out of bed these days.', 'predicted_label': 1, 'confidence': 0.31701788306236267}\n",
      "\n",
      "Thought: I keep overthinking every conversation I had today.\n",
      "Sentiment: {'text': 'I keep overthinking every conversation I had today.', 'predicted_label': 1, 'confidence': 0.3087787330150604}\n",
      "\n",
      "Thought: I feel hopeless and don’t see much point in continuing like this.\n",
      "Sentiment: {'text': 'I feel hopeless and don’t see much point in continuing like this.', 'predicted_label': 1, 'confidence': 0.29416424036026}\n",
      "\n",
      "Thought: Spent time with friends today and genuinely enjoyed it.\n",
      "Sentiment: {'text': 'Spent time with friends today and genuinely enjoyed it.', 'predicted_label': 0, 'confidence': 0.33869314193725586}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentiments = []\n",
    "for s in thoughts:\n",
    "    sentiments.append(predict_sentiment(s))\n",
    "\n",
    "for thought, sentiment in zip(thoughts, sentiments):\n",
    "    print(f\"Thought: {thought}\")\n",
    "    print(f\"Sentiment: {sentiment}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f34175b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
